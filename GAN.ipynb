{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gogowonji/080239/blob/master/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wUYf7vzejL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f1686fd-0ec1-4b28-f20b-3e48d9c99b1e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGmhoUu2fJxx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69c742de-e09c-4266-fffa-9a734d8ba08d"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.7.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.7.0\n",
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 24 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 38.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.13.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.42.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=3d0d7bca25cc212d7856c92509e911237738505833d0040e84d944b4961fcc42\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKYmWhswTbpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597cc76a-0551-4c23-8276-156f18c82110"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data\", one_hot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DrBGizyrnz4"
      },
      "source": [
        "total_epoch = 100\n",
        "batch_size = 100\n",
        "learning_rate = 0.0000651\n",
        "n_hidden = 256\n",
        "n_hidden2 = 128\n",
        "n_input = 28 * 28\n",
        "n_noise = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGmu8_FSTwlN"
      },
      "source": [
        "X = tf.placeholder(tf.float32, [None, n_input])\n",
        "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
        "\n",
        "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
        "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
        "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_hidden2], stddev=0.01))\n",
        "G_b2 = tf.Variable(tf.zeros([n_hidden2]))\n",
        "G_W3 = tf.Variable(tf.random_normal([n_hidden2, n_hidden], stddev=0.01))\n",
        "G_b3 = tf.Variable(tf.zeros([n_hidden]))\n",
        "G_W4 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
        "G_b4 = tf.Variable(tf.zeros([n_input]))\n",
        "\n",
        "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
        "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
        "D_W2 = tf.Variable(tf.random_normal([n_hidden, n_hidden2], stddev=0.01))\n",
        "D_b2 = tf.Variable(tf.zeros([n_hidden2]))\n",
        "D_W3 = tf.Variable(tf.random_normal([n_hidden2, 1], stddev=0.01))\n",
        "D_b3 = tf.Variable(tf.zeros([1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH2nmsGXskzx"
      },
      "source": [
        "def generator(noise_z):\n",
        "  hidden1 = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
        "  hidden2 = tf.nn.relu(tf.matmul(hidden1, G_W2) + G_b2)\n",
        "  hidden3 = tf.nn.relu(tf.matmul(hidden2, G_W3) + G_b3)\n",
        "  output = tf.nn.sigmoid(tf.matmul(hidden3, G_W4) + G_b4)\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKnwmNTys0Bd"
      },
      "source": [
        "def discriminator(inputs):\n",
        "  hidden1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "  hidden2 = tf.nn.relu(tf.matmul(hidden1, D_W2) + D_b2)\n",
        "  output = tf.nn.sigmoid(tf.matmul(hidden2, D_W3) + D_b3)\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIOVHvg2tBFo"
      },
      "source": [
        "def get_noise(batch_size, n_noise):\n",
        "  return np.random.normal(size=(batch_size, n_noise))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqDBSZ6ltIeG"
      },
      "source": [
        "G = generator(Z)\n",
        "D_gene = discriminator(G)\n",
        "D_real = discriminator(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dqIF2wqtQAQ"
      },
      "source": [
        "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_gene))\n",
        "loss_G = tf.reduce_mean(tf.log(D_gene))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SQqubVXUgzt"
      },
      "source": [
        "D_var_list = [D_W1, D_b1, D_W2, D_b2, D_W3, D_b3]\n",
        "G_var_list = [G_W1, G_b1, G_W2, G_b2, G_W3, G_b3, G_W4, G_b4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag_kK1uQU9EN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1d78f6-f828-4252-b3a1-5c9d6a794e7b"
      },
      "source": [
        "train_D = tf.train.RMSPropOptimizer(learning_rate).minimize(-loss_D, var_list=D_var_list)\n",
        "train_G = tf.train.RMSPropOptimizer(learning_rate).minimize(-loss_G, var_list=G_var_list)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "loss_val_D, loss_val_G = 0, 0\n",
        "\n",
        "for epoch in range(total_epoch):\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    noise = get_noise(batch_size, n_noise)\n",
        "    \n",
        "    _, loss_val_D = sess.run([train_D, loss_D], feed_dict={X: batch_xs, Z: noise})\n",
        "    _, loss_val_G = sess.run([train_G, loss_G], feed_dict={Z: noise})\n",
        "  \n",
        "  if epoch == 0 or (epoch + 1) % 10 == 0:\n",
        "    print('Epoch:', '%04d' % epoch, 'D loss: {:.4}'.format(loss_val_D), \n",
        "        'G loss: {:.4}'.format(loss_val_G))\n",
        "\n",
        "  # 확인용 이미지 생성\n",
        "\n",
        "  if epoch == 0 or (epoch + 1) % 10 == 0:\n",
        "    sample_size = 10\n",
        "    noise = get_noise(sample_size, n_noise)\n",
        "    samples = sess.run(G, feed_dict={Z: noise})\n",
        "\n",
        "    fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
        "\n",
        "    for i in range(sample_size):\n",
        "      ax[i].set_axis_off()\n",
        "      ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
        "\n",
        "    plt.savefig('./samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
        "    \n",
        "    plt.close(fig)\n",
        "\n",
        "print('최적화 완료!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0000 D loss: -1.107 G loss: -1.514\n",
            "Epoch: 0009 D loss: -1.187 G loss: -1.032\n",
            "Epoch: 0019 D loss: -1.209 G loss: -1.055\n",
            "Epoch: 0029 D loss: -1.115 G loss: -1.017\n",
            "Epoch: 0039 D loss: -1.114 G loss: -0.9722\n",
            "Epoch: 0049 D loss: -1.557 G loss: -0.5658\n",
            "Epoch: 0059 D loss: -1.166 G loss: -0.7622\n",
            "Epoch: 0069 D loss: -1.001 G loss: -1.426\n",
            "Epoch: 0079 D loss: -0.2726 G loss: -2.814\n",
            "Epoch: 0089 D loss: -0.05561 G loss: -4.536\n",
            "Epoch: 0099 D loss: -0.09655 G loss: -3.646\n",
            "최적화 완료!\n"
          ]
        }
      ]
    }
  ]
}